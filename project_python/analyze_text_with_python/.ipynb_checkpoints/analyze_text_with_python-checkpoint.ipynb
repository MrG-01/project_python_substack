{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b120867-974b-412f-8ca8-f8d9895a6d97",
   "metadata": {},
   "source": [
    "### Analyze Text With Python\n",
    "\t \n",
    "#### Project Overview ðŸ’¡\n",
    "\n",
    "In this project, you'll build a simple text analyzer in Python. You'll learn how to process text, count words, sentences, and characters, and identify the most frequent word. This is a great exercise in string manipulation and working with dictionaries.\n",
    "Challenge Yourself!\n",
    "\n",
    "#### Task:\n",
    "\n",
    "Write a Python script that takes a user-inputted block of text and analyzes it by calculating the number of characters, words, and sentences. Additionally, determine the most frequently used word and calculate the average word and sentence length.\n",
    "\n",
    "#### Expected Output:\n",
    "\n",
    "The program should output text statistics, including:\n",
    "\n",
    "* Total Characters\n",
    "* Total Words\n",
    "* Total Sentences\n",
    "* Most Frequent Word\n",
    "* Average Word Length\n",
    "* Average Sentence Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5d565300-5751-4a11-900c-0f9ce7048d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    def WordFreq(self, s:str) -> int:\\n\\n    def AvgWordLen(self, s:str) -> int:\\n\\n    def AvgSentLen(self, s:str) -> int:\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "class Parser:\n",
    "\n",
    "    def SentParse(self, paragraph:str) -> list:\n",
    "\n",
    "        exclude_apostrophes = string.punctuation.replace(\"'\", \"\")\n",
    "\n",
    "        sentence_enders = r\"[\" + re.escape(exclude_apostrophes) + r\"]+\"\n",
    "\n",
    "        sentences = re.split(sentence_enders + r\"\\s*\", paragraph)\n",
    "\n",
    "        return sentences\n",
    "\n",
    "    def SentCount(self, sentence_list:list) -> int:\n",
    "\n",
    "        count = 0\n",
    "\n",
    "        for sentence in sentence_list:\n",
    "\n",
    "            count += 1\n",
    "\n",
    "        return count\n",
    "\n",
    "    def WordParse(self, paragraph:str) -> list:  \n",
    "        \n",
    "        # Split by spaces or punctuation marks\n",
    "        split_pattern = r\"[\\s\" + re.escape(string.punctuation) + r\"]+\"\n",
    "\n",
    "        # Split the paragraph using the pattern\n",
    "        tokens = re.split(split_pattern, paragraph)\n",
    "\n",
    "        # Filter out any empty strings that might result from consecutive delimiters\n",
    "        tokens = [token for token in tokens if token]\n",
    "\n",
    "        return tokens\n",
    "    \n",
    "    def WordCount(self, words:list) -> int:\n",
    "\n",
    "        count = 0\n",
    "\n",
    "        for word in range(len(words)):\n",
    "\n",
    "            count += 1\n",
    "            \n",
    "        return count\n",
    "        \n",
    "\"\"\"\n",
    "    def WordFreq(self, s:str) -> int:\n",
    "\n",
    "    def AvgWordLen(self, s:str) -> int:\n",
    "\n",
    "    def AvgSentLen(self, s:str) -> int:\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c3733e93-8fef-4dd0-b27c-e03a8bf8fcd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /opt/conda/lib/python3.12/site-packages (3.8.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.12/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.12/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.12/site-packages (from spacy) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.12/site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.12/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /opt/conda/lib/python3.12/site-packages (from spacy) (8.3.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.12/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.12/site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.12/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/conda/lib/python3.12/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/conda/lib/python3.12/site-packages (from spacy) (0.15.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.12/site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.12/site-packages (from spacy) (2.2.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.12/site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.12/site-packages (from spacy) (2.10.6)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from spacy) (75.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from spacy) (24.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.12/site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in /opt/conda/lib/python3.12/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/conda/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /opt/conda/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
      "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.2.1)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (14.0.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/conda/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/conda/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->spacy) (3.0.2)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\n",
      "Requirement already satisfied: wrapt in /opt/conda/lib/python3.12/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "618b41bd-f6ae-436a-ac93-c04107b744e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import spacy\n",
    "from collections import Counter\n",
    "\n",
    "# Load SpaCy model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "class Parser:\n",
    "\n",
    "    def SentParse(self, paragraph:str) -> list:\n",
    "\n",
    "        doc = nlp(paragraph)\n",
    "        \n",
    "        sentences = [sent.text for sent in doc.sents]\n",
    "\n",
    "        return sentences\n",
    "        \n",
    "    def SentCount(self, sentence_list:list) -> int:\n",
    "\n",
    "        count = 0\n",
    "\n",
    "        for sentence in sentence_list:\n",
    "\n",
    "            count += 1\n",
    "\n",
    "        return count\n",
    "\n",
    "    def WordParse(self, paragraph:str) -> list:  \n",
    "\n",
    "        # Create a translation table to remove punctuation\n",
    "        translator = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "        # Remove punctuation from the string\n",
    "        text_without_punctuation = paragraph.translate(translator)\n",
    "        \n",
    "        # Process the text with spaCy\n",
    "        doc = nlp(text_without_punctuation)\n",
    "\n",
    "        # Iterate through the Doc object to get individual tokens (words)\n",
    "        words = [token.text for token in doc]\n",
    "\n",
    "        return words\n",
    "\n",
    "    def WordCount(self, words:list) -> int:\n",
    "\n",
    "        count = 0\n",
    "\n",
    "        for word in range(len(words)):\n",
    "\n",
    "            count += 1\n",
    "            \n",
    "        return count\n",
    "        \n",
    "    def MostFreqWord (self, paragraph:str) -> str:\n",
    "\n",
    "        # Create a translation table to remove punctuation\n",
    "        translator = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "        # Remove punctuation from the string\n",
    "        text_without_punctuation = paragraph.translate(translator)\n",
    "\n",
    "        doc = nlp(text_without_punctuation)\n",
    "\n",
    "        # Create a list to store the words (excluding stop words and punctuation)\n",
    "        all_words = []\n",
    "        for token in doc:\n",
    "            if not token.is_stop and not token.is_punct:\n",
    "                all_words.append(token.text.lower())  # Convert to lowercase for case-insensitive counting\n",
    "\n",
    "        word_counts = Counter(all_words)\n",
    "\n",
    "        most_common = word_counts.most_common(1)[0]\n",
    "\n",
    "        return most_common        \n",
    "        \n",
    "\n",
    "    def AvgWordLen(self, paragraph:str) -> int:\n",
    "\n",
    "        # Create a translation table to remove punctuation\n",
    "        translator = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "        # Remove punctuation from the string\n",
    "        text_without_punctuation = paragraph.translate(translator)\n",
    "\n",
    "        doc = nlp(text_without_punctuation)\n",
    "\n",
    "        # Create a list to store the words (excluding stop words and punctuation)\n",
    "        all_words = []\n",
    "        for token in doc:\n",
    "            if not token.is_stop and not token.is_punct:\n",
    "                all_words.append(token.text.lower())  # Convert to lowercase for case-insensitive counting\n",
    "\n",
    "        word_counts = Counter(all_words)\n",
    "\n",
    "        total_length = 0\n",
    "        total_count = 0\n",
    "        \n",
    "        for word, count in word_counts.items():\n",
    "            total_length += len(word) * count\n",
    "            total_count += count\n",
    "\n",
    "        if total_count > 0:\n",
    "            average_length = total_length / total_count\n",
    "        else:\n",
    "            print(\"No words to calculate the average length from.\")\n",
    "\n",
    "        return average_length\n",
    "    \n",
    "\n",
    "    def AvgSentLen(self, paragraph:str) -> int:\n",
    "\n",
    "        if not paragraph:\n",
    "            return 0.0  # Handle empty input\n",
    "\n",
    "        doc = nlp(paragraph)\n",
    "        \n",
    "        sentences = list(doc.sents)  # Convert the generator to a list\n",
    "\n",
    "        total_words = 0\n",
    "        num_sentences = len(sentences)\n",
    "\n",
    "        for sent in sentences:\n",
    "            # Tokenize each sentence to count the words\n",
    "            words = [token for token in sent if not token.is_space] # Exclude spaces\n",
    "            total_words += len(words)\n",
    "\n",
    "        if num_sentences > 0:\n",
    "            average_words_per_sentence = total_words / num_sentences\n",
    "            return average_words_per_sentence\n",
    "        else:\n",
    "            return 0.0 # Handle case with no sentences\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2bb1fd28-0575-4568-8050-e5ee4b0cee94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paragraph: This is the first sentence. Here's the second sentence! And this is the third? Some sentences might have abbreviations like Mr. Smith.\n",
      "The sentence count is 4 sentences.\n",
      "The word count is 22 words.\n",
      "The most frequent word is ('sentence', 2)\n",
      "The average word length is 6.67 characters.\n",
      "The average sentence length is 6.75 words.\n"
     ]
    }
   ],
   "source": [
    "parser = Parser()\n",
    "\n",
    "paragraph = r\"This is the first sentence. Here's the second sentence! And this is the third? Some sentences might have abbreviations like Mr. Smith.\"\n",
    "print(f\"Paragraph: {paragraph}\")\n",
    "\n",
    "sentences = parser.SentParse(paragraph)\n",
    "sent_count = parser.SentCount(sentences)\n",
    "print(f\"The sentence count is {sent_count} sentences.\")\n",
    "\n",
    "words = parser.WordParse(paragraph)\n",
    "word_count = parser.WordCount(words)\n",
    "print(f\"The word count is {word_count} words.\")\n",
    "\n",
    "most_freq_word = parser.MostFreqWord(paragraph)\n",
    "print(f\"The most frequent word is {most_freq_word}\")\n",
    "\n",
    "avg_word_length = parser.AvgWordLen(paragraph)\n",
    "print(f\"The average word length is {avg_word_length:.2f} characters.\")\n",
    "\n",
    "avg_sentence_length = parser.AvgSentLen(paragraph)\n",
    "print(f\"The average sentence length is {avg_sentence_length:.2f} words.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
